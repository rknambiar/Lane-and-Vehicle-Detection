{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detector Initialized\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from sklearn import linear_model\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util\n",
    "\n",
    "\n",
    "def extract_lane(road_lines):\n",
    "    left_lane = []\n",
    "    right_lane = []\n",
    "    left_slope = []\n",
    "    right_slope = []\n",
    "\n",
    "    if road_lines is not None:\n",
    "        for x in range(0, len(road_lines)):\n",
    "            for x1,y1,x2,y2 in road_lines[x]:\n",
    "                slope = compute_slope(x1,y1,x2,y2)\n",
    "                if (slope < 0):\n",
    "                    left_lane.append(road_lines[x])\n",
    "                    left_slope.append(slope)\n",
    "                else:\n",
    "                    if (slope > 0):\n",
    "                        right_lane.append(road_lines[x])\n",
    "                        right_slope.append(slope)\n",
    "                \n",
    "    return left_lane, right_lane , left_slope, right_slope\n",
    "    \n",
    "#Compute slope of the line when points are given\n",
    "def compute_slope(x1,y1,x2,y2):\n",
    "    if x2!=x1:\n",
    "        return ((y2-y1)/(x2-x1))\n",
    "\n",
    "def print_lanes(left_lane, right_lane, left_slope, right_slope):\n",
    "    #print(\"Left lane\")\n",
    "    for x in range(0, len(left_lane)):\n",
    "        print(left_lane[x], left_slope[x])\n",
    "    #print(\"Right lane\")\n",
    "    for x in range(0, len(right_lane)):\n",
    "        print(right_lane[x], right_slope[x])\n",
    "\n",
    "def split_append(left_lane, right_lane):\n",
    "    left_lane_sa = []\n",
    "    right_lane_sa = []\n",
    "    \n",
    "    for x in range(0, len(left_lane)):\n",
    "        for x1,y1,x2,y2 in left_lane[x]:\n",
    "            left_lane_sa.append([x1, y1])\n",
    "            left_lane_sa.append([x2, y2])\n",
    "\n",
    "    for y in range(0, len(right_lane)):\n",
    "        for x1,y1,x2,y2 in right_lane[y]:\n",
    "            right_lane_sa.append([x1,y1])\n",
    "            right_lane_sa.append([x2,y2])\n",
    "            \n",
    "    left_lane_sa = np.array(left_lane_sa)\n",
    "    right_lane_sa = np.array(right_lane_sa)\n",
    "    left_lane_sa,right_lane_sa = sort(left_lane_sa,right_lane_sa)\n",
    "    return left_lane_sa,right_lane_sa\n",
    "\n",
    "#This fucntion prints the lanes after the frame is split and merged\n",
    "def print_lanes_sa(left_lane_sa, right_lane_sa):\n",
    "    #print(\"Left lane\")\n",
    "    for x in range(0, len(left_lane_sa)):\n",
    "        print(left_lane_sa[x])\n",
    "    #print(\"Right lane\")\n",
    "    for x in range(0, len(right_lane_sa)):\n",
    "        print(right_lane_sa[x])          \n",
    "\n",
    "def sort(left_lane_sa,right_lane_sa):\n",
    "    left_lane_sa = left_lane_sa[np.argsort(left_lane_sa[:, 0])]\n",
    "    right_lane_sa = right_lane_sa[np.argsort(right_lane_sa[:, 0])]\n",
    "\n",
    "    return left_lane_sa, right_lane_sa\n",
    "\n",
    "def draw_lanes(left_lane_sa, right_lane_sa, frame):\n",
    "    (vx_left,vy_left,x0_left,y0_left) = cv2.fitLine(left_lane_sa,cv2.DIST_L2,0,0.01,0.01)\n",
    "    (vx_right,vy_right,x0_right,y0_right) = cv2.fitLine(right_lane_sa,cv2.DIST_L2,0,0.01,0.01)\n",
    "    left_len = len(left_lane_sa)\n",
    "    right_len = len(right_lane_sa)\n",
    "    slope_left = vy_left / vx_left\n",
    "    slope_right = vy_right / vx_right\n",
    "    intercept_left = y0_left - (slope_left * x0_left)\n",
    "    intercept_right = y0_right - (slope_right * x0_right)\n",
    "\n",
    "    ysize = frame.shape[0]\n",
    "    xsize = frame.shape[1]\n",
    "    y_limit_low = int(0.95*ysize)\n",
    "    y_limit_high = int(0.65*ysize)\n",
    "\n",
    "    #Coordinates for point 1(Bottom Left)\n",
    "    y_1 = ysize\n",
    "    x_1 = int((y_1-intercept_left)/slope_left)\n",
    "\n",
    "    #Coordinates for point 2(Bottom Left)\n",
    "    y_2 = y_limit_high\n",
    "    x_2 = int((y_2-intercept_left)/slope_left)\n",
    "\n",
    "    #Coordinates for point 3(Bottom Left)\n",
    "    y_3 = y_limit_high\n",
    "    x_3 = int((y_3-intercept_right)/slope_right)\n",
    "    \n",
    "    #Coordinates for point 4(Bottom Right)\n",
    "    y_4 = ysize\n",
    "    x_4 = int((y_4-intercept_right)/slope_right)\n",
    "\n",
    "    #Draw lines\n",
    "    cv2.line(frame,(x_1,y_1),(x_2,y_2),(0,255,255),3)\n",
    "    cv2.line(frame,(x_3,y_3),(x_4,y_4),(0,255,255),3)\n",
    "    pts = np.array([[x_1, y_1], [x_2, y_2], [x_3, y_3], [x_4, y_4]])\n",
    "    mask_color = (255,255,0)\n",
    "    frame_copy = frame.copy()\n",
    "    cv2.fillPoly(frame_copy, np.int32([pts]), mask_color)\n",
    "    opacity = 0.4\n",
    "    cv2.addWeighted(frame_copy,opacity,frame,1-opacity,0,frame)\n",
    "\n",
    "    #Print Routine\n",
    "    #print(intercept_left,slope_left,intercept_right,slope_right)\n",
    "\n",
    "def ransac_drawlane(left_lane_sa, right_lane_sa,frame):\n",
    "    left_lane_x = []\n",
    "    left_lane_y = []\n",
    "    right_lane_x = []\n",
    "    right_lane_y = []\n",
    "\n",
    "    for x1,y1 in left_lane_sa:\n",
    "        left_lane_x.append([x1])\n",
    "        left_lane_y.append([y1])\n",
    "\n",
    "    for x1,y1 in right_lane_sa:\n",
    "        right_lane_x.append([x1])\n",
    "        right_lane_y.append([y1])\n",
    "\n",
    "    left_ransac_x = np.array(left_lane_x)\n",
    "    left_ransac_y = np.array(left_lane_y)\n",
    "\n",
    "    right_ransac_x = np.array(right_lane_x)\n",
    "    right_ransac_y = np.array(right_lane_y)\n",
    "\n",
    "        \n",
    "    left_ransac = linear_model.RANSACRegressor(linear_model.LinearRegression())\n",
    "    #print(left_ransac_x,left_ransac_y,len(left_ransac_x),len(left_ransac_y), left_ransac_x.shape )\n",
    "    left_ransac.fit(left_ransac_x, left_ransac_y)\n",
    "    slope_left = left_ransac.estimator_.coef_\n",
    "    intercept_left = left_ransac.estimator_.intercept_\n",
    "\n",
    "    right_ransac = linear_model.RANSACRegressor()\n",
    "    right_ransac.fit(right_ransac_x, right_ransac_y)\n",
    "    slope_right = right_ransac.estimator_.coef_\n",
    "    intercept_right = right_ransac.estimator_.intercept_\n",
    "\n",
    "    ysize = frame.shape[0]\n",
    "    xsize = frame.shape[1]\n",
    "    y_limit_low = int(0.95*ysize)\n",
    "    y_limit_high = int(0.65*ysize)\n",
    "\n",
    "    #Coordinates for point 1(Bottom Left)\n",
    "    y_1 = ysize\n",
    "    x_1 = int((y_1-intercept_left)/slope_left)\n",
    "\n",
    "    #Coordinates for point 2(Bottom Left)\n",
    "    y_2 = y_limit_high\n",
    "    x_2 = int((y_2-intercept_left)/slope_left)\n",
    "\n",
    "    #Coordinates for point 3(Bottom Left)\n",
    "    y_3 = y_limit_high\n",
    "    x_3 = int((y_3-intercept_right)/slope_right)\n",
    "    \n",
    "    #Coordinates for point 4(Bottom Right)\n",
    "    y_4 = ysize\n",
    "    x_4 = int((y_4-intercept_right)/slope_right)\n",
    "\n",
    "    cv2.line(frame,(x_1,y_1),(x_2,y_2),(0,255,255),3)\n",
    "    cv2.line(frame,(x_3,y_3),(x_4,y_4),(0,255,255),3)\n",
    "    pts = np.array([[x_1, y_1], [x_2, y_2], [x_3, y_3], [x_4, y_4]])\n",
    "    mask_color = (255,255,0)\n",
    "    frame_copy = frame.copy()\n",
    "    cv2.fillPoly(frame_copy, np.int32([pts]), mask_color)\n",
    "    opacity = 0.4\n",
    "    cv2.addWeighted(frame_copy,opacity,frame,1-opacity,0,frame)\n",
    "    return frame\n",
    "              \n",
    "def initializeObjectDetector():\n",
    "    \n",
    "    \n",
    "    return  detection_graph\n",
    "\n",
    "def detectObject(frame, sess, detection_graph):\n",
    "    image_np = frame\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    # Definite input and output Tensors for detection_graph\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "    # Each box represents a part of the image where a particular object was detected.\n",
    "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    # Each score represent how level of confidence for each of the objects.\n",
    "    # Score is shown on the result image, together with the class label.\n",
    "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "      \n",
    "      \n",
    "    # Actual detection.\n",
    "    (boxes, scores, classes, num) = sess.run(\n",
    "          [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "          feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np,\n",
    "          np.squeeze(boxes),\n",
    "          np.squeeze(classes).astype(np.int32),\n",
    "          np.squeeze(scores),\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          line_thickness=8)\n",
    "    return image_np\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    cap = cv2.VideoCapture('challenge.mp4')\n",
    "    MODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\n",
    "    MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "    DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "    # Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "    PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "\n",
    "    # List of the strings that is used to add correct label for each box.\n",
    "    PATH_TO_LABELS = os.path.join('data', 'mscoco_label_map.pbtxt')\n",
    "    NUM_CLASSES = 90\n",
    "\n",
    "    # ## Load a (frozen) Tensorflow model into memory.\n",
    "\n",
    "    detection_graph = tf.Graph()\n",
    "    with detection_graph.as_default():\n",
    "      od_graph_def = tf.GraphDef()\n",
    "      with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')\n",
    "\n",
    "\n",
    "    # ## Loading label map\n",
    "    # Label maps map indices to category names, so that when our convolution network predicts `5`, we know that this corresponds to `airplane`.  Here we use internal utility functions, but anything that returns a dictionary mapping integers to appropriate string labels would be fine\n",
    "\n",
    "    label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "    # ## Helper code\n",
    "\n",
    "    def load_image_into_numpy_array(image):\n",
    "      (im_width, im_height) = image.size\n",
    "      return np.array(image.getdata()).reshape(\n",
    "          (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "    # Size, in inches, of the output images.\n",
    "    IMAGE_SIZE = (12, 8)\n",
    "    \n",
    "    print('Detector Initialized')\n",
    "    with detection_graph.as_default():\n",
    "      with tf.Session(graph=detection_graph) as sess:\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            #Escape when no frame is captured / End of Video\n",
    "            if frame is None:\n",
    "                break\n",
    "\n",
    "            # Color space conversion\n",
    "            img_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            img_hsv = cv2. cvtColor(frame, cv2.COLOR_BGR2HLS)\n",
    "            ysize = img_gray.shape[0]\n",
    "            xsize = img_gray.shape[1]\n",
    "\n",
    "            #Detecting yellow and white colors\n",
    "            low_yellow = np.array([20, 100, 100])\n",
    "            high_yellow = np.array([30, 255, 255])\n",
    "            mask_yellow = cv2.inRange(img_hsv, low_yellow, high_yellow)\n",
    "            mask_white = cv2.inRange(img_gray, 200, 255)\n",
    "\n",
    "            mask_yw = cv2.bitwise_or(mask_yellow, mask_white)\n",
    "            mask_onimage = cv2.bitwise_and(img_gray, mask_yw)\n",
    "\n",
    "            #Smoothing for removing noise\n",
    "            gray_blur = cv2.GaussianBlur(mask_onimage, (5,5), 0)\n",
    "\n",
    "            #Region of Interest Extraction\n",
    "            mask_roi = np.zeros(img_gray.shape, dtype=np.uint8) \n",
    "            left_bottom = [0, ysize]\n",
    "            right_bottom = [xsize-0, ysize]\n",
    "            apex_left = [((xsize/2)-50), ((ysize/2)+50)]\n",
    "            apex_right = [((xsize/2)+50), ((ysize/2)+50)]\n",
    "            mask_color = 255\n",
    "            roi_corners = np.array([[left_bottom, apex_left, apex_right, right_bottom]], dtype=np.int32)\n",
    "            cv2.fillPoly(mask_roi, roi_corners, mask_color)\n",
    "            image_roi = cv2.bitwise_and(gray_blur, mask_roi)\n",
    "\n",
    "            #Thresholding before edge\n",
    "            ret, img_postthresh = cv2.threshold(image_roi, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            #Use canny edge detection\n",
    "            edge_low = 50\n",
    "            edge_high = 200\n",
    "            img_edge = cv2.Canny(img_postthresh, edge_low, edge_high)\n",
    "\n",
    "            #Hough Line Draw\n",
    "            minLength = 20\n",
    "            maxGap = 10\n",
    "            road_lines = cv2.HoughLinesP(img_postthresh, 1, np.pi/180, 20, minLength, maxGap)\n",
    "            left_lane, right_lane, left_slope, right_slope = extract_lane(road_lines)\n",
    "            left_lane_sa, right_lane_sa = split_append(left_lane, right_lane)\n",
    "            #draw_lanes(left_lane_sa, right_lane_sa,frame)\n",
    "            image_np = ransac_drawlane(left_lane_sa, right_lane_sa,frame)\n",
    "\n",
    "            #Object Detection Pipeline\n",
    "            \n",
    "            #frame = detectObject(frame, sess, detection_graph)\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            # Definite input and output Tensors for detection_graph\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            # Each box represents a part of the image where a particular object was detected.\n",
    "            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            # Each score represent how level of confidence for each of the objects.\n",
    "            # Score is shown on the result image, together with the class label.\n",
    "            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "      \n",
    "      \n",
    "            # Actual detection.\n",
    "            (boxes, scores, classes, num) = sess.run(\n",
    "              [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "              feed_dict={image_tensor: image_np_expanded})\n",
    "        \n",
    "            # Visualization of the results of a detection.\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "              image_np,\n",
    "              np.squeeze(boxes),\n",
    "              np.squeeze(classes).astype(np.int32),\n",
    "              np.squeeze(scores),\n",
    "              category_index,\n",
    "              use_normalized_coordinates=True,\n",
    "              line_thickness=8)\n",
    "            cv2.imshow('Detect',cv2.resize(image_np,(800,600)))\n",
    "            cv2.imshow('Post Threshold',img_postthresh)\n",
    "            if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
